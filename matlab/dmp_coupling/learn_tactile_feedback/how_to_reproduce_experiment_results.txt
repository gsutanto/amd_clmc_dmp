Execution Order for Reproducing Experimental Results:
**--------------------- Learning Nominal Primitives ---------------------**
 [1] Collect baseline/nominal human demonstrations (no coupling terms),
     for example by executing the client program from controller_manager_examples_arm catkin package:
     $ ./test_dmp_learn_tactile_feedback_scraping_controller right
     and then select option 'a' (activate gravity compensation).
     Save the dataset/data files for example inside the folder ~/Desktop/dmp_demos/scraping_w_tool/human_baseline/ .
 [2] Making sure that 'specific_task_type' variable is set correctly,
     segment the baseline/nominal human demonstrations into primitives, 
     by executing the script amd_clmc_dmp/data/dmp_coupling/learn_tactile_feedback/align_and_segment_nominal_sensorimotor_trajs_scraping.m .
 [3] Making sure that 'specific_task_type' variable is set correctly,
     learn the baseline/nominal primitives from the segmented demonstrations,
     by executing the script amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/learn_nominal_action_primitives.m
 [4] Making sure that 'specific_task_type' variable is set correctly,
     convert the learned baseline/nominal primitives' parameters from MATLAB *.m file into *.txt files for loading by C++ program, 
     by executing the script amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/convert_nominal_action_dmp_params_mat2cpp.m .
     The parameters as *.txt files will be stored for example under directory amd_clmc_dmp/data/dmp_coupling/learn_tactile_feedback/scraping_w_tool/learned_prims_params/ .
**---------------- Learning Feedback/Coupling Term Model for Unrolling on Robot ----------------**
 [5] Making sure that 'prims_param_root_dir_path' string is set correctly,
     i.e. including the correct sub-string component (e.g. 'scraping_w_tool') as specific task type identifier,
     collect baseline/nominal sensory traces by letting the robot unroll the learned baseline/nominal primitives under baseline/nominal environment setting.
     This is done for example by turning OFF force control for compliance (such that correction demonstration is possible) 
     in one/several control dimension(s) during RightArmDMPScrapingCorrectableBaselineUnrollingController execution, by setting the flag:
       is_allowing_correction: 0
     in controller_manager_arm catkin package, 
     file controller_manager_arm/controller_manager_task_arm/config/controller_manager/controllers/RightArmDMPScrapingCorrectableBaselineUnrollingController.yaml ;
     and then executing the client program from controller_manager_examples_arm catkin package:
     $ ./test_dmp_learn_tactile_feedback_scraping_controller right
     and then select option 'u' (unroll baseline/nominal primitive, uncorrectable because force control is turned OFF, so only position control is performed).
     Save the dataset/data files for example inside the folder ~/Desktop/dmp_demos/scraping_w_tool/baseline/ .
 [6] Collect corrected sensorimotor demonstrations (believed to contain the coupling terms),
     by letting the robot unroll the learned baseline/nominal primitives under various environment settings,
     and while doing so, the human performs active corrections as necessary, e.g. in primitives 2 and 3.
     This is done for example by turning ON force control for compliance (such that correction demonstration is possible) 
     in one/several control dimension(s) during RightArmDMPScrapingCorrectableBaselineUnrollingController execution, by setting the flag:
       is_allowing_correction: 1
     in controller_manager_arm catkin package, 
     file controller_manager_arm/controller_manager_task_arm/config/controller_manager/controllers/RightArmDMPScrapingCorrectableBaselineUnrollingController.yaml ;
     and then executing the client program from controller_manager_examples_arm catkin package:
     $ ./test_dmp_learn_tactile_feedback_scraping_controller right
     and then select option 'u' (unroll baseline/nominal primitive, correctable by humans because force control is turned ON, so both position and force controls are performed).
     Save the dataset/data files for example inside the folder ~/Desktop/dmp_demos/scraping_w_tool/<setting_number>/ .
 [7] Making sure that 'specific_task_type' variable is set correctly,
     segment the corrected sensorimotor demonstrations into primitives, 
     by executing the script amd_clmc_dmp/data/dmp_coupling/learn_tactile_feedback/segment_sensorimotor_trajs_scraping_v2.m .
 [8] Making sure that 'specific_task_type' variable is set correctly,
     prepare the Training and Generalization Testing Dataset, by running the following scripts in amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/:
     >> on MATLAB: convert_demo_segment_to_supervised_tactile_fb_dataset_v2.m 
                   => augment_dataset.m (please remember to select which electrode(s) are being used, 
                                         by setting the appropriate values for 
                                         is_using_R_LF_electrodes and is_using_R_RF_electrodes flags in this script file...)
                   => augment_outlier_metric_and_visualize_2D_data_projection.m 
                   => tf_tactile_data_preparation_robot_unroll.m
 [9] Perform Feedback Model Training in TensorFlow in Python:
     >> on Spyder: amd_clmc_dmp/python/dmp_coupling/learn_tactile_feedback/learn_tactile_feedback_w_PMNN.py
     (ensuring (is_performing_generalization_test == 0) on line 49 is selected...)
[10] Using helper script amd_clmc_dmp/python/dmp_coupling/learn_tactile_feedback/models/compare_nmse_generalization_among_reinits.m ,
     for EACH x in [1,2,3], inspect and compare among the prim_<x>_nmse_reinit_<y>_step_<TF_max_train_iters>.mat files for y in [0,1,2], 
     and manually select y which has the best (lowest) nmse_generalization_test.
     Suppose for x==1, y=2;
             for x==2, y=0;
             for x==3, y=1;
     then write/update the file amd_clmc_dmp/python/dmp_coupling/learn_tactile_feedback/models/reinit_selection_idx.txt with content:
     "2 0 1" (without the double quotes when writing in the file of course...).
[11] Execute the script amd_clmc_dmp/data/dmp_coupling/learn_tactile_feedback/scraping/update_data_after_TF_training.m .
[12] Test the trained Feedback Model performing prediction on unseen demonstration/trial in TensorFlow in Python:
     >> on Spyder: amd_clmc_dmp/python/dmp_coupling/learn_tactile_feedback/test_learned_tactile_feedback_w_PMNN.py
[13] Execute TensorFlow Python versus MATLAB prediction based on trained parameters, by running the following scripts in amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/:
     >> on MATLAB: test_TensorFlow_trained_NN_model.m
[14] For safety during real robot unrolling with trained Feedback Model, we compute the safety bounds,
     by executing the script amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/analyze_trajectory_statistics.m .
**------------------- Unrolling both Learned Primitive ------------------*
 *---------- and Learned Feedback/Coupling Term Model on Robot ----------*
 *------------------- and Evaluation by Visualization -------------------**
[15] Test the learned coupling term by unrolling it together with 
     the learned baseline/nominal primitives on the robot, 
     under a variety of environment settings (especially non-nominal/non-baseline settings).
     This is done for example by executing the client program from controller_manager_examples_arm catkin package:
     $ ./test_dmp_learn_tactile_feedback_scraping_controller right
     and then select option 'c' (unroll primitive and learned coupling term).
     Save the dataset/data files for example inside the folder 
     ~/Desktop/dmp_robot_unroll_results/scraping/<date_and_description>/robot/
     <p (positive tiltboard angle) or n (negative tiltboard angle)><tiltboard angle>/
     <c (unrolling with coupling term) or b (unrolling baseline/without coupling term)>/ .
[16] Segment the robot unrolling results into primitives, 
     by executing the script amd_clmc_dmp/data/dmp_coupling/learn_tactile_feedback/segment_robot_unroll_data_scraping.m .
[17] Visualize the robot unrolling results (divided into primitives),
     by executing the script amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/analyze_robot_unroll_data.m .
**---------------- (Generalization) Evaluation on Learning Feedback/Coupling Term Model ----------------**
(same steps as Section "Learning Feedback/Coupling Term Model for Unrolling on Robot" above until step [8])
 [9] Making sure that 'specific_task_type' variable is set correctly,
     prepare the Training and Generalization Testing Datasets, by running the following scripts in amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/:
     >> on MATLAB: tf_tactile_data_preparation_generalization_evaluation.m
[10] Perform Feedback Model Training in TensorFlow in Python:
     >> on Spyder: amd_clmc_dmp/python/dmp_coupling/learn_tactile_feedback/learn_tactile_feedback_w_PMNN.py
     (ensuring (is_performing_generalization_test == 1) on line 49 is selected, and
      ensuring appropriate input_selector_list on line 61 is selected...)
[11] Compute average best-generalization NMSE, 
     by running the following scripts in amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/:
     >> on MATLAB: average_best_generalization_nmse.m
**-------------------- Miscellaneous Visualizations --------------------**
All are located under amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/ :
[a] visualize_demo_vs_extracted_supervised_dataset_across_trials.m :
    Visualize the trajectories, as well as extracted supervised dataset
    (target X (sensor input) - Ct/coupling term (output) pairs) 
    overlayed together across trials in each setting to observe inconsistency.
[b] visualize_extracted_supervised_dataset_across_settings.m :
    Visualize the extracted supervised dataset
    (target X (sensor input) - Ct/coupling term (output) pairs) 
    overlayed together across settings to observe how these dataset
    transitions from one setting to another.
[c] visualize_predicted_vs_target_ct.m :
    Visualize the predicted vs target coupling term (Ct),
    especially on trials it has never seen before,
    for evaluating the fitting/prediction quality,
    as well as generalization to unseen data.
[d] amd_clmc_dmp/matlab/dmp_coupling/learn_tactile_feedback/neural_nets/plot_final_regular_hidden_layer_feature_priority_evolution.m :
    Visualize the top 10 dominant regular hidden layer features 
    for each phase RBF in the specified primitive, roll-orientation coupling term,
    displayed in yellow. The less dominant ones are displayed in blue.
    Should be run AFTER executing steps [1]-[14] above.
